'use client';

import { useState, useEffect, useCallback, useRef } from 'react';
import { initTensorFlow } from '@/lib/ai/tensorflow';

// ìì„¸ íƒ€ì…
export type PostureType =
  | 'upright'     // ë°”ë¥¸ ìì„¸
  | 'leaning_left'  // ì™¼ìª½ìœ¼ë¡œ ê¸°ìš¸ì–´ì§
  | 'leaning_right' // ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê¸°ìš¸ì–´ì§
  | 'slouching'   // êµ¬ë¶€ì •í•œ ìì„¸
  | 'unknown';    // ê°ì§€ ë¶ˆê°€

// ìì„¸ ê¸°ë¡
export interface PostureRecord {
  timestamp: number;
  posture: PostureType;
  tiltAngle: number; // ê¸°ìš¸ê¸° ê°ë„ (ë„)
  questionIndex?: number;
}

// ìì„¸ í†µê³„
export interface PostureStats {
  uprightPercentage: number;
  leftTiltPercentage: number;
  rightTiltPercentage: number;
  slouchingPercentage: number;
  totalTiltCount: number;
  avgTiltDuration: number; // ms
}

// í›… ì˜µì…˜
interface UsePoseDetectionOptions {
  enabled?: boolean;
  detectionInterval?: number;
  tiltThreshold?: number; // ê¸°ìš¸ê¸° ì„ê³„ê°’ (ë„)
  onPostureChange?: (posture: PostureType, angle: number) => void;
}

// í›… ë°˜í™˜ íƒ€ì…
interface UsePoseDetectionReturn {
  isLoading: boolean;
  isActive: boolean;
  currentPosture: PostureType;
  currentTiltAngle: number;
  postureTimeline: PostureRecord[];
  postureStats: PostureStats;
  videoRef: React.RefObject<HTMLVideoElement | null>;
  startDetection: () => Promise<boolean>;
  stopDetection: () => void;
  clearTimeline: () => void;
  recordPostureForQuestion: (questionIndex: number) => void;
}

export function usePoseDetection(options: UsePoseDetectionOptions = {}): UsePoseDetectionReturn {
  const {
    enabled = true,
    detectionInterval = 500,
    tiltThreshold = 15,
    onPostureChange,
  } = options;

  const [isLoading, setIsLoading] = useState(false);
  const [isActive, setIsActive] = useState(false);
  const [currentPosture, setCurrentPosture] = useState<PostureType>('unknown');
  const [currentTiltAngle, setCurrentTiltAngle] = useState(0);
  const [postureTimeline, setPostureTimeline] = useState<PostureRecord[]>([]);

  const videoRef = useRef<HTMLVideoElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const detectionIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const currentQuestionIndexRef = useRef<number>(0);

  // ìì„¸ í†µê³„ ê³„ì‚°
  const postureStats = calculatePostureStats(postureTimeline);

  // ì›¹ìº  ìŠ¤íŠ¸ë¦¼ ì‹œì‘
  const startWebcam = useCallback(async (): Promise<boolean> => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 640 },
          height: { ideal: 480 },
          facingMode: 'user',
        },
        audio: false,
      });

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        await videoRef.current.play();
      }

      streamRef.current = stream;
      return true;
    } catch (error) {
      console.error('[PoseDetection] Webcam access denied:', error);
      return false;
    }
  }, []);

  // ì›¹ìº  ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€
  const stopWebcam = useCallback(() => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }
  }, []);

  // ìì„¸ ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)
  // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” pose-detection ëª¨ë¸ë¡œ ì–´ê¹¨/ë¨¸ë¦¬ ìœ„ì¹˜ ë¶„ì„
  const analyzePosture = useCallback((): { posture: PostureType; angle: number } => {
    // ëœë¤ ê¸°ìš¸ê¸° ì‹œë®¬ë ˆì´ì…˜ (-30 ~ +30ë„)
    // ëŒ€ë¶€ë¶„ ë°”ë¥¸ ìì„¸, ê°€ë” ê¸°ìš¸ì–´ì§
    const isUpright = Math.random() > 0.2; // 80% í™•ë¥ ë¡œ ë°”ë¥¸ ìì„¸

    if (isUpright) {
      const angle = (Math.random() - 0.5) * 10; // -5 ~ +5ë„
      return { posture: 'upright', angle };
    }

    // ê¸°ìš¸ì–´ì§„ ê²½ìš°
    const angle = (Math.random() - 0.5) * 40; // -20 ~ +20ë„

    let posture: PostureType;
    if (Math.abs(angle) > tiltThreshold) {
      posture = angle < 0 ? 'leaning_left' : 'leaning_right';
    } else {
      posture = 'upright';
    }

    return { posture, angle };
  }, [tiltThreshold]);

  // ìì„¸ ê°ì§€ ë£¨í”„
  const detectPosture = useCallback(() => {
    if (!isActive || !videoRef.current) return;

    const { posture, angle } = analyzePosture();

    setCurrentPosture(posture);
    setCurrentTiltAngle(angle);

    // íƒ€ì„ë¼ì¸ì— ê¸°ë¡
    const record: PostureRecord = {
      timestamp: Date.now(),
      posture,
      tiltAngle: angle,
      questionIndex: currentQuestionIndexRef.current,
    };

    setPostureTimeline(prev => [...prev, record]);

    // ì½œë°± í˜¸ì¶œ
    if (onPostureChange) {
      onPostureChange(posture, angle);
    }
  }, [isActive, analyzePosture, onPostureChange]);

  // ê°ì§€ ì‹œì‘
  const startDetection = useCallback(async (): Promise<boolean> => {
    if (!enabled) return false;

    setIsLoading(true);

    try {
      // TensorFlow.js ì´ˆê¸°í™”
      await initTensorFlow();

      // ì›¹ìº  ì‹œì‘
      const webcamStarted = await startWebcam();
      if (!webcamStarted) {
        setIsLoading(false);
        return false;
      }

      setIsActive(true);
      setIsLoading(false);

      // ê°ì§€ ì¸í„°ë²Œ ì‹œì‘
      detectionIntervalRef.current = setInterval(detectPosture, detectionInterval);

      return true;
    } catch (error) {
      console.error('[PoseDetection] Failed to start:', error);
      setIsLoading(false);
      return false;
    }
  }, [enabled, startWebcam, detectPosture, detectionInterval]);

  // ê°ì§€ ì¤‘ì§€
  const stopDetection = useCallback(() => {
    setIsActive(false);

    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
      detectionIntervalRef.current = null;
    }

    stopWebcam();
  }, [stopWebcam]);

  // íƒ€ì„ë¼ì¸ ì´ˆê¸°í™”
  const clearTimeline = useCallback(() => {
    setPostureTimeline([]);
  }, []);

  // íŠ¹ì • ë¬¸í•­ì˜ ìì„¸ ê¸°ë¡
  const recordPostureForQuestion = useCallback((questionIndex: number) => {
    currentQuestionIndexRef.current = questionIndex;
  }, []);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopDetection();
    };
  }, [stopDetection]);

  // ê°ì§€ ë£¨í”„ ì—…ë°ì´íŠ¸
  useEffect(() => {
    if (isActive && !detectionIntervalRef.current) {
      detectionIntervalRef.current = setInterval(detectPosture, detectionInterval);
    }

    return () => {
      if (detectionIntervalRef.current) {
        clearInterval(detectionIntervalRef.current);
        detectionIntervalRef.current = null;
      }
    };
  }, [isActive, detectPosture, detectionInterval]);

  return {
    isLoading,
    isActive,
    currentPosture,
    currentTiltAngle,
    postureTimeline,
    postureStats,
    videoRef,
    startDetection,
    stopDetection,
    clearTimeline,
    recordPostureForQuestion,
  };
}

// ìì„¸ í†µê³„ ê³„ì‚° ìœ í‹¸ë¦¬í‹°
function calculatePostureStats(timeline: PostureRecord[]): PostureStats {
  if (timeline.length === 0) {
    return {
      uprightPercentage: 0,
      leftTiltPercentage: 0,
      rightTiltPercentage: 0,
      slouchingPercentage: 0,
      totalTiltCount: 0,
      avgTiltDuration: 0,
    };
  }

  const total = timeline.length;
  let upright = 0;
  let leftTilt = 0;
  let rightTilt = 0;
  let slouching = 0;

  // ê¸°ìš¸ì–´ì§ êµ¬ê°„ ê³„ì‚°
  let tiltSequences: number[] = [];
  let currentTiltStart: number | null = null;

  timeline.forEach((record, index) => {
    switch (record.posture) {
      case 'upright':
        upright++;
        if (currentTiltStart !== null) {
          // ê¸°ìš¸ì–´ì§ êµ¬ê°„ ì¢…ë£Œ
          tiltSequences.push(record.timestamp - currentTiltStart);
          currentTiltStart = null;
        }
        break;
      case 'leaning_left':
        leftTilt++;
        if (currentTiltStart === null) {
          currentTiltStart = record.timestamp;
        }
        break;
      case 'leaning_right':
        rightTilt++;
        if (currentTiltStart === null) {
          currentTiltStart = record.timestamp;
        }
        break;
      case 'slouching':
        slouching++;
        break;
    }

    // ë§ˆì§€ë§‰ ê¸°ë¡ì—ì„œ ê¸°ìš¸ì–´ì§ ì¤‘ì´ë©´ ì¢…ë£Œ
    if (index === timeline.length - 1 && currentTiltStart !== null) {
      tiltSequences.push(record.timestamp - currentTiltStart);
    }
  });

  const avgTiltDuration = tiltSequences.length > 0
    ? tiltSequences.reduce((a, b) => a + b, 0) / tiltSequences.length
    : 0;

  return {
    uprightPercentage: Math.round((upright / total) * 100),
    leftTiltPercentage: Math.round((leftTilt / total) * 100),
    rightTiltPercentage: Math.round((rightTilt / total) * 100),
    slouchingPercentage: Math.round((slouching / total) * 100),
    totalTiltCount: tiltSequences.length,
    avgTiltDuration: Math.round(avgTiltDuration),
  };
}

// ìì„¸ ì´ë¦„ í•œê¸€í™”
export const postureLabels: Record<PostureType, string> = {
  upright: 'ë°”ë¥¸ ìì„¸',
  leaning_left: 'ì™¼ìª½ ê¸°ìš¸ì„',
  leaning_right: 'ì˜¤ë¥¸ìª½ ê¸°ìš¸ì„',
  slouching: 'êµ¬ë¶€ì •í•¨',
  unknown: 'ê°ì§€ ë¶ˆê°€',
};

// ìì„¸ ì•„ì´ì½˜
export const postureIcons: Record<PostureType, string> = {
  upright: 'ğŸ§˜',
  leaning_left: 'â†–ï¸',
  leaning_right: 'â†—ï¸',
  slouching: 'ğŸª‘',
  unknown: 'â“',
};

// ìì„¸ ìƒ‰ìƒ
export const postureColors: Record<PostureType, string> = {
  upright: '#10B981',
  leaning_left: '#F59E0B',
  leaning_right: '#F59E0B',
  slouching: '#EF4444',
  unknown: '#6B7280',
};

// ëª©í‘œ ìì„¸ ì •ì˜
export interface TargetPose {
  name: string;
  keypoints: Record<string, { x: number; y: number; minConfidence?: number }>;
  tolerance: number; // í—ˆìš© ì˜¤ì°¨ (í”½ì…€)
}

// ìì„¸ ë¹„êµ ê²°ê³¼
export interface PoseComparisonResult {
  isMatching: boolean;
  matchScore: number; // 0-100
  matchedPoints: string[];
  unmatchedPoints: string[];
}

/**
 * ëª©í‘œ ìì„¸ì™€ í˜„ì¬ ìì„¸ ë¹„êµ
 * @param target ëª©í‘œ ìì„¸ ì •ì˜
 * @param currentKeypoints í˜„ì¬ ê°ì§€ëœ í‚¤í¬ì¸íŠ¸
 * @returns ë¹„êµ ê²°ê³¼
 */
export function comparePose(
  target: TargetPose,
  currentKeypoints: Record<string, { x: number; y: number; confidence: number }>
): PoseComparisonResult {
  const targetPoints = Object.keys(target.keypoints);
  const matchedPoints: string[] = [];
  const unmatchedPoints: string[] = [];

  for (const pointName of targetPoints) {
    const targetPoint = target.keypoints[pointName];
    const currentPoint = currentKeypoints[pointName];

    if (!currentPoint) {
      unmatchedPoints.push(pointName);
      continue;
    }

    // ì‹ ë¢°ë„ í™•ì¸
    const minConfidence = targetPoint.minConfidence || 0.5;
    if (currentPoint.confidence < minConfidence) {
      unmatchedPoints.push(pointName);
      continue;
    }

    // ìœ„ì¹˜ ë¹„êµ (í—ˆìš© ì˜¤ì°¨ ë‚´)
    const distance = Math.sqrt(
      Math.pow(currentPoint.x - targetPoint.x, 2) +
      Math.pow(currentPoint.y - targetPoint.y, 2)
    );

    if (distance <= target.tolerance) {
      matchedPoints.push(pointName);
    } else {
      unmatchedPoints.push(pointName);
    }
  }

  const matchScore = targetPoints.length > 0
    ? Math.round((matchedPoints.length / targetPoints.length) * 100)
    : 0;

  return {
    isMatching: matchScore >= 70, // 70% ì´ìƒ ì¼ì¹˜í•˜ë©´ ì„±ê³µ
    matchScore,
    matchedPoints,
    unmatchedPoints,
  };
}

/**
 * ê°„ë‹¨í•œ ë™ì‘ ê°ì§€ (ì‹œë®¬ë ˆì´ì…˜ìš©)
 * ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” TensorFlow.js pose-detection ì‚¬ìš©
 */
export function detectSimpleMovement(
  movementType: string,
  _videoElement: HTMLVideoElement | null
): { detected: boolean; confidence: number } {
  // ì‹œë®¬ë ˆì´ì…˜: 80% í™•ë¥ ë¡œ ë™ì‘ ê°ì§€ ì„±ê³µ
  const detected = Math.random() > 0.2;
  const confidence = detected ? 0.7 + Math.random() * 0.3 : 0.2 + Math.random() * 0.3;

  return { detected, confidence };
}

/**
 * ë™ì‘ ì¼ì¹˜ë„ ì ìˆ˜ ê³„ì‚°
 * @param targetMovement ëª©í‘œ ë™ì‘ íƒ€ì…
 * @param detectionHistory ê°ì§€ ì´ë ¥
 * @param duration ìˆ˜í–‰ ì‹œê°„ (ms)
 * @returns ì ìˆ˜ (0-100)
 */
export function calculateMovementScore(
  targetMovement: string,
  detectionHistory: Array<{ detected: boolean; confidence: number; timestamp: number }>,
  duration: number
): number {
  if (detectionHistory.length === 0) return 0;

  // ê°ì§€ ì„±ê³µë¥ 
  const successRate = detectionHistory.filter(d => d.detected).length / detectionHistory.length;

  // í‰ê·  ì‹ ë¢°ë„
  const avgConfidence = detectionHistory.reduce((sum, d) => sum + d.confidence, 0) / detectionHistory.length;

  // ê¸°ë³¸ ì ìˆ˜ = ì„±ê³µë¥  * 80 + ì‹ ë¢°ë„ * 20
  const baseScore = successRate * 80 + avgConfidence * 20;

  return Math.round(Math.min(baseScore, 100));
}

export default usePoseDetection;
